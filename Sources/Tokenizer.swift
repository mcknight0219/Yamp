 //
 // Tokenzier.swift 
 //
 // Copyright (c) 2017 Qiang, Guo <mcknight0219@gmail.com>
 // Author: Qiang, Guo <mcknight0219@gmail.com>
 //
 // Permission is hereby granted, free of charge, to any person obtaining a copy of
 // this software and associated documentation files (the "Software"), to deal in
 // the Software without restriction, including without limitation the rights to
 // use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
 // the Software, and to permit persons to whom the Software is furnished to do so,
 // subject to the following conditions:
 //
 // The above copyright notice and this permission notice shall be included in all
 // copies or substantial portions of the Software.
 //
 // THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 // IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
 // FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
 // COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
 // IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 // CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 //

import Foundation

/// Possible tokens generated by tokenizer
public enum Token: Equatable {
	case word(String)
	// Non-alphanum characters
	case marker(String)
	// tabs, whitespaces, and etc.
	case whitespace(String)
	// important so not included in .whitespace
	case newline
}

public func ==(a: Token, b: Token) -> Bool {
	switch (a, b) {
	case (.word(let x), .word(let y)) where x == y:
		return true
	case (.marker(let x), .marker(let y)) where x == y:
		return true
	case (.whitespace(let x), .whitespace(let y)) where x == y:
		return true
	case (.newline, .newline):
		return true
	default:
		return false
	}
}

public class Tokenizer {	

	/// the target to be tokenzied
	let text: String!

	/// the current index
	var cur: String.Index

	/// markers avaiable to markdown
	let markers = "_*^#~[]()`>"
	
	/// Initialize a tokenizer
	///
	/// - Parameters:
	///		= text: the target string
	///		= range: specify range of text to be processed
	///
	public init(_ text: String, range: Range<String.Index>? = nil) {
		guard range != nil else {
			self.text = text
			self.cur = self.text.startIndex
			return
		}

		let r = range!
		self.text = text.substring(with: r)
		self.cur = self.text.startIndex
	}
	
    /// Return the next token
    ///
	public func next() -> Token? {
		guard hasNext() else {
			return nil
		}

		return glob()
	}

    /// If tokenizer has reached the end
    ///
	public func hasNext() -> Bool {
		return self.cur < self.text.endIndex
	}

    /// Reset the cur to starIndex
	public func rewind() -> Void {
        self.cur = self.text.startIndex
	}


    // MARK: Implementation
    
	/// Return character under current cursor
    /// Note: Alwasy assume index is within range.
	func currentCharacter() -> String {
		return String(self.text[self.cur])
	}

	/// Get next token
	func glob() -> Token {
		let c = currentCharacter()

		if c.isWs() {
			let start = cur
			while hasNext() && currentCharacter().isWs() {
				cur = self.text.index(after: cur)
			}
            return .whitespace(self.text.substring(from: start, to: cur)!)
		}
        
        
        if c == "\n" {
            // glob as many new line as possible
            let start = cur
			while hasNext() && currentCharacter() == "\n" {
				cur = self.text.index(after: cur)
			}
			return .newline
        }

		if markers.range(of: c) != nil {
			cur = self.text.index(after: cur)
			return .marker(c)
		} else {
			/// Glob until whitespace/newline/markers
			let start = cur
			while hasNext() {
				cur = self.text.index(after: cur)
				if cur == self.text.endIndex {
					break
				}

				let char = currentCharacter()
				if char.isWs() || char == "\n" || markers.range(of: char) != nil {
					break
				}
			}
			return .word(self.text.substring(from: start, to: cur)!)
		}
	}

}
